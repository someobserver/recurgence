---
layout: page
title: "Pathologies"
description: "A taxonomy of pathologies in recursive systems"
permalink: /pathologies/
parent: "pathologies"
created_date: 2025-06-18
updated_date: 2025-06-18
---

All recursive systems are subject to the same failures, each with an identifiable, quantifiable, maladaptive pattern.

Coherence without wisdom starts shouting conspiracies. Coherence without humility ends in ridiculous hubris. Humility without coherence winds up paralyzed in the face of meaning.

Recurgent Field Theory models the geometric failure modes where the making of meaning breaks down. Every one here has a lived pattern of dysfunction we can easily recognize in ourselves, our relationships, our institutions, and our technologies. Consider:

- A fundamentalist movement is rife with **Attractor Dogmatism** — meaning that's gotten so crystallized in its own unshakeable certainty, it resists *prima facie* evidence.

- A person with severe ADHD [writer's note: hi] might experience **Attractor Splintering** — too many possible focuses competing for attention without the constraint to choose between them.

- A closed social media platform exhibits **Recurgent Parasitism** — feeding its own growth by extracting both attention and [semantic mass](/explanations/s/semantic-mass) from human relationships.

The signatures appear whether the case study is individual psychology, group dynamics, institutional behavior, media, or artificial intelligence. Recursive systemic failure modes are universal because they're emergent from the same geometric constraints governing the coherence, stability, and evolution of inter-observer meaning.

This document is a recognition of these patterns: recursive, self-referential systems operate according to discoverable principles with characteristic manners of breaking down. When we can quantify the pattern, we can name the pathology.

Naming a pathology is always the first step to understanding its solutions.

## Rigidity Pathologies

Feelings of strength and certainty often accompany one of the rigidity modes, but that's only half of what makes them nasty. From the outside, the system can appear entirely stable, coherent, and at times even wise—until suddenly it's not. Eventually it encounters a situation requiring its adaptation, at which point it either collapses under its own certitude (typically spectacularly), or it doubles down on the dissonance (pathologically).

These are always the product of over-constraint. Whatever structures ordinarily metabolize incoming complexity into stabilized meaning have gotten themselves so rigidly anchored in the past, they prevent adaptation altogether, ultimately leading to collapse.

### Attractor Dogmatism

These are meaning structures so stable and monolithic they refuse to be moved, regardless of the incoming information. Think: political ideologies explaining away contradictory information until their cognitive dissonance finally reaches a breaking point, forcing meaning to reorganize. Cults land squarely here as well, particularly ones that require disengagement from others and a refusal to integrate updated empirical knowledge.

This mode is *usually* pretty identifiable to a reasonable outside observer. Often, these feel strong and coherent from the inside, until **`click`** all of a sudden the veil drops. It's when reality requires reference that their brittleness either starts to show, or coherence finally reorganizes entirely.

Signatures:  

- $A(p,t) > A_{\text{crit}}$ = attractor stability breaks critical threshold
- $\|\nabla V(C)\| \gg \Phi(C)$ = the force holding a subsystem in the attractor outpaces the generative force that could've created new meaning from new information

See [Global Attractors and Bifurcation Geometry](/math/09-recurgent-field-equations/attractors-and-transitions/) for overstabilization and other attractor evolution dynamics.

### Belief Calcification  

This is the mathematical translation of: *"Well, that's the way we've always done it"* = a system that's grown partially or entirely unresponsive to actionable feedback.

It's not so much that the system rejects new information, it's that in this mode, it just literally can't process it. This looks like trauma responses interpreting neutral scenarios as threatening. It feels like depression that doesn't register any positive feedback. This can be seen in AI systems stuck in localized minima.

Signature:

$$
\lim_{\epsilon \to 0} \frac{dC}{dt}\bigg|_{C+\epsilon} \approx 0
$$

For more, [Agents and Interpretation](/math/09-recurgent-field-equations/05-agents-and-interpretation/) includes the functional derivative perspective and math formulae for coherence responsiveness to perturbation.

### Metric Crystallization

Of the three, this is the most subtle and the most insidious. It's where the geometry of meaning is more or less frozen, even though there's recursive pressure trying to change it. The "distance" between concepts is fixed, with no capacity to update. Effectively, system's developed such strong constraints governing how meaning is allowed to transform, the transformation pathways themselves become fossilized.

This lands in personal habits that feel impossible to quit, and in relationship patterns that persist despite glowing evidence of dysfunction. Organizations end up with this pathology as procedures outlast their purpose, leaving employees wondering, *"...so, how do I trust the purpose of anything I do here?"*

Signatures:

- $\frac{\partial g_{ij}}{\partial t} \to 0$ = the semantic geometry becomes fixed—concepts that should've been able to move closer or further apart based on new experience simply can't
- $R_{ij} \neq 0$ = the system still "wants" to adapt (there's recursive pressure building), but the constraints have become so rigid that adaptation pathways get blocked.

For more: [Semantic Manifold and Metric Geometry](/math/03-semantic-manifold/)


## Fragmentation Pathologies

These are at the opposite pole from rigidity. Instead of being hardened beyond its own usefulness, in this case, meaning is more like wet concrete that never sets in the first place. All the ingredients are there, but nothing stabilizes into lasting form.

The main issue is insifficient constraint density $\rho(p,t)$ allows meaning to flow all over the place, without enough boundaries channeling it into lasting structure. Instead of one solid attractor, this results in numerous competing possibilities that never quite substantively coalesce.

In other words, remove $N$ banks from a river and it'll dissipate into a useless swamp.

### Attractor Splintering

Imagine opening a restaurant menu to find 100 options, each with 100 manual customizations for each item. What seems like ultimate choice becomes the death of it: the abundance of possibility quickly becomes its own kind of prison.

A person with ADHD lives this pathology as their daily reality. With a low threshold for detecting interesting patterns (high sensitivity to $\Phi(C)$), their attention system generates new attractor possibilities at a rate far exceeding the executive capacity to stabilize any one pattern into genuine depth.

The attention economy profits directly from attractor splintering. Every app and website wants to be your new notifier, next attractor, next habit to compete with your existing interests. What's termed "engagement" is the systematic prevention of meaningful engagement with any one thing.

$\frac{dN_{\text{attractors}}}{dt} > \kappa \cdot \frac{d\Phi(C)}{dt}$

### Coherence Dissolution

This is meaning, hemorrhaging. Coherence Dissolution is the dangerous, structural breakdown where complexity dissolves semantic coherence faster than it can stabilize. The other two Fragmentation Pathologies are passive, lending to multiple competing attractors—in this case, coherence itself is *actively* dissipating.

**The dissolution consuming the system's stabilizing mechanisms is self-reinforcing, and what makes this a dangerous, runaway problem.**

It presents in information systems overloaded beyond their processing or network capacity. You can recognize it in social feeds where the volume of incoming content monopolizes awareness, but prevents sustained focus or integrated understanding. It shows up in research, with publication pressure generating such a rapid turnover of ideas, no one concept has time to develop proper teeth before it's displaced by the next trend or abstraction.

Organizations experiencing rapid restructuring can enter Coherence Dissolution if their institutional knowledge, relationships, and procedures break down faster than they can be replaced. Even at the C-suite level, the capacity for *anyone* to understand what's happening becomes compromised by the rate of change itself.

$$
\|\nabla C\| \gg \|C\|, \quad \frac{d^2C}{dt^2} > 0
$$

In math terms, $\|\nabla C\|$ represents the sharpness of coherence change across the manifold. When that gradient overwhelms the coherence itself, that's an indication *meaning* (noun) is hemorrhaging faster than it can stabilize. The second condition, $\frac{d^2C}{dt^2} > 0$, tells us the hemorrhaging is getting exponentially worse.

### Reference Decay

When insights stop talking to each other, knowledge begins to archipelago. The threads holding together a coherent reference frame slowly fade, one by one.

It doesn't typically feel dangerous from the inside, because the facts are all still there. You still know stuff. Institutions can still mostly function. Society operates, for a while. And all the while, structural resilience is slowly hemmorrhaging.

When crisis hits a healthy system with intact recursive coupling, insights can propagate rapidly. Solutions discovered in one domain quickly jump to others, past experience informs present decisions, and collective intelligence emerges.

But when recursive coupling has decayed, each part of the system faces threats in isolation. Crisis becomes incoherent mayhem because the connections that would have normally enabled coordinated response have already been severed.

**Reference Decay is an early warning indicator of approaching Coherence Dissolution.**

$\frac{d\|R_{ijk}\|}{dt} < 0$ (no compensatory mechanism)

## Inflation Pathologies

These are semantic cancer—what happens when the autopoietic potential $\Phi(C)$ breaks free from the constraints that are supposed to (or used to) regulate it. Through sheer generative force, the result of malignant coherence is often a loss of touch with objective reality.

Just like real cancer, these three configurations hijack normal mechanisms, reinforce themselves, drain resources, lose regulatory sensitivity, and then metastasize through the host system.

In every case, the system becomes *enthusiastically* wrong.

### Delusional Expansion
$\Phi(C) \gg V(C), \quad \mathcal{H}[R] \approx 0, \quad W(p,t) < W_{\text{min}}$

### Semantic Hypercoherence
$C(p,t) > C_{\text{max}}, \quad \oint_{\partial \Omega} F_i \cdot dS^i < F_{\text{leakage}}$

### Recurgent Parasitism
$\frac{d}{dt}\int_{\Omega} M(p,t) \, dV_p > 0, \quad \frac{d}{dt}\int_{\mathcal{M}\setminus\Omega} M(p,t) \, dV_p < 0$

## Observer-Coupling Pathologies

When something goes wrong with the interpretation operator $\mathcal{I}_{\psi}$, the system can end up in a state where it's not able to make sense of the world. This is the observer-coupling pathologies.

### Paranoid Interpretation
$\hat{C}_{\psi}(q,t) \ll C(q,t), \quad \forall q \in \mathcal{Q}$

### Reality Decoupling
$\frac{\|R_{ijk}(p,p,t)\|}{\int_q \|R_{ijk}(p,q,t)\| \, dq} \to 1$

### Semantic Narcissism
$\|\mathcal{I}_{\psi}[C] - C\| > \tau \|C\|$
